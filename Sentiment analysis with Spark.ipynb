{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b20f3ba",
   "metadata": {
    "id": "oC70FwzAbT0L"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e941bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a151fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e979e9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master = 'local', appName = 'project_1')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675df713",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('shopee').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe72fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('thoi_trang_nam.csv', inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cfddc21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------+------------+------------------+------+--------------------+\n",
      "|_c0|product_id|      category|sub_category|              user|rating|             comment|\n",
      "+---+----------+--------------+------------+------------------+------+--------------------+\n",
      "|  0|         0|Thời Trang Nam|    Áo Ba Lỗ|      karmakyun2nd|     5|                kiểm|\n",
      "|  1|         0|Thời Trang Nam|    Áo Ba Lỗ|  tranquangvinh_vv|     5|cho_phép sơ_suất ...|\n",
      "|  2|         0|Thời Trang Nam|    Áo Ba Lỗ|nguyenquoctoan2005|     5|vừa_vặn nâu dày đ...|\n",
      "|  3|         0|Thời Trang Nam|    Áo Ba Lỗ|    nguyenthuyhavi|     5|        đầu_shop hợp|\n",
      "|  4|         0|Thời Trang Nam|    Áo Ba Lỗ|      luonganh5595|     5|đẹp form đẹp hàng...|\n",
      "+---+----------+--------------+------------+------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a253f8",
   "metadata": {},
   "source": [
    "### Clean and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0ff1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- sub_category: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- comment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c65b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_null_data = data.filter(data.comment.isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d027eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81965"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_null_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "328aadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter(data.comment.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a026ee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455985"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f35f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('class', when(data.rating >= 4, 'like')\n",
    "                               .when(data.rating <= 2, 'not_like')\n",
    "                               .otherwise('neutral'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a934f202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------------------+-----+\n",
      "|sub_category|rating|             comment|class|\n",
      "+------------+------+--------------------+-----+\n",
      "|    Áo Ba Lỗ|     5|                kiểm| like|\n",
      "|    Áo Ba Lỗ|     5|cho_phép sơ_suất ...| like|\n",
      "|    Áo Ba Lỗ|     5|vừa_vặn nâu dày đ...| like|\n",
      "|    Áo Ba Lỗ|     5|        đầu_shop hợp| like|\n",
      "|    Áo Ba Lỗ|     5|đẹp form đẹp hàng...| like|\n",
      "+------------+------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.drop('_c0', 'product_id', 'category', 'user')\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f053b84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------------------+-----+\n",
      "|sub_category|rating|             comment|class|\n",
      "+------------+------+--------------------+-----+\n",
      "|    Áo Ba Lỗ|     5|                kiểm| like|\n",
      "|    Áo Ba Lỗ|     5|cho_phép sơ_suất ...| like|\n",
      "|    Áo Ba Lỗ|     5|vừa_vặn nâu dày đ...| like|\n",
      "|    Áo Ba Lỗ|     5|        đầu_shop hợp| like|\n",
      "|    Áo Ba Lỗ|     5|đẹp form đẹp hàng...| like|\n",
      "+------------+------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "506a7b3a",
   "metadata": {
    "id": "QAaUq3Y46vrg"
   },
   "outputs": [],
   "source": [
    "data = data.withColumn('length', length(data['comment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "365204ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------------------+-----+------+\n",
      "|sub_category|rating|             comment|class|length|\n",
      "+------------+------+--------------------+-----+------+\n",
      "|    Áo Ba Lỗ|     5|                kiểm| like|     4|\n",
      "|    Áo Ba Lỗ|     5|cho_phép sơ_suất ...| like|    44|\n",
      "|    Áo Ba Lỗ|     5|vừa_vặn nâu dày đ...| like|    50|\n",
      "|    Áo Ba Lỗ|     5|        đầu_shop hợp| like|    12|\n",
      "|    Áo Ba Lỗ|     5|đẹp form đẹp hàng...| like|    23|\n",
      "|    Áo Ba Lỗ|     5|đẹp chất_lượng dà...| like|    22|\n",
      "|    Áo Ba Lỗ|     5|  sáu_mươi_lăm luônn| like|    18|\n",
      "|    Áo Ba Lỗ|     5|            quên học| like|     8|\n",
      "|    Áo Ba Lỗ|     5|             chê hợp| like|     7|\n",
      "|    Áo Ba Lỗ|     5|gọn_gàng đẹp ôm kâng| like|    20|\n",
      "+------------+------+--------------------+-----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a149446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+\n",
      "|   class|       avg(rating)|       avg(length)|\n",
      "+--------+------------------+------------------+\n",
      "|not_like|1.3522262123000426| 18.58215514427061|\n",
      "| neutral|               3.0|15.654778101716877|\n",
      "|    like| 4.862014461683805|20.912028217413194|\n",
      "+--------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pretty Clear Difference\n",
    "data.groupby('class').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2811047c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|   class| count|\n",
      "+--------+------+\n",
      "|not_like| 39821|\n",
      "| neutral| 30870|\n",
      "|    like|385294|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupby('class').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db5b30c",
   "metadata": {},
   "source": [
    "### Feature Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77287488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StringIndexer\n",
    "tokenizer = Tokenizer(inputCol = 'comment', outputCol = 'token_text')\n",
    "stopremove = StopWordsRemover(inputCol = 'token_text', outputCol = 'stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol = 'stop_tokens', outputCol = 'c_vec')\n",
    "idf = IDF(inputCol = 'c_vec', outputCol = 'tf_idf')\n",
    "class_to_num = StringIndexer(inputCol = 'class', outputCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7ba7f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b616324",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = VectorAssembler(inputCols = ['tf_idf', 'length'],\n",
    "                          outputCol = 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917657fd",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a7334b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01eb7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipe = Pipeline(stages = [class_to_num, \n",
    "                                   tokenizer,\n",
    "                                   stopremove,\n",
    "                                   count_vec,\n",
    "                                   idf,\n",
    "                                   clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc92ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipe.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04bb4538",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = cleaner.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674143e",
   "metadata": {},
   "source": [
    "#### Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3708197",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data.select(['label', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24389bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(29328,[148,29327...|\n",
      "|  0.0|(29328,[618,1043,...|\n",
      "|  0.0|(29328,[0,7,12,25...|\n",
      "|  0.0|(29328,[61,995,29...|\n",
      "|  0.0|(29328,[0,8,33,50...|\n",
      "|  0.0|(29328,[0,17,46,2...|\n",
      "|  0.0|(29328,[1760,2373...|\n",
      "|  0.0|(29328,[185,192,2...|\n",
      "|  0.0|(29328,[61,81,293...|\n",
      "|  0.0|(29328,[0,71,541,...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "665e1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, testing) = clean_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e95ee96",
   "metadata": {},
   "source": [
    "## NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15b9adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2767b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use defauls\n",
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46ab2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbModel = nb.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cfd76a",
   "metadata": {},
   "source": [
    "### Đánh giá kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ed70d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for evaluating classification model\n",
    "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator\n",
    "\n",
    "accuracy= MulticlassClassificationEvaluator(labelCol= 'label', predictionCol= 'prediction', metricName= 'accuracy')\n",
    "f1= MulticlassClassificationEvaluator(labelCol= 'label', predictionCol= 'prediction', metricName= 'f1')\n",
    "\n",
    "def classification_evaluator(data_result):\n",
    "    data_result.crosstab(col1 = 'prediction', col2= 'label').show()\n",
    "    print('accuracy:' ,accuracy.evaluate(data_result))\n",
    "    print('f1:' ,f1.evaluate(data_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093f2dc",
   "metadata": {},
   "source": [
    "#### Đánh giá model dựa trên tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d27544d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data set\n",
    "nb_train_model= nbModel.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e8f621a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+-----+-----+\n",
      "|prediction_label|   0.0|  1.0|  2.0|\n",
      "+----------------+------+-----+-----+\n",
      "|             2.0| 24470| 4712|14380|\n",
      "|             1.0|  9683|20628| 3411|\n",
      "|             0.0|235626| 2616| 4015|\n",
      "+----------------+------+-----+-----+\n",
      "\n",
      "accuracy: 0.8469460882953987\n",
      "f1: 0.8655681354901851\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator(nb_train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b02f5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.87      0.92    269779\n",
      "         1.0       0.61      0.74      0.67     27956\n",
      "         2.0       0.33      0.66      0.44     21806\n",
      "\n",
      "    accuracy                           0.85    319541\n",
      "   macro avg       0.64      0.76      0.68    319541\n",
      "weighted avg       0.90      0.85      0.87    319541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = nb_train_model.select(['label']).collect()\n",
    "y_pred = nb_train_model.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caec4be6",
   "metadata": {},
   "source": [
    "#### Đánh giá model dựa trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84ef4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data set\n",
    "nb_test_model= nbModel.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b285c3c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----+----+\n",
      "|prediction_label|  0.0| 1.0| 2.0|\n",
      "+----------------+-----+----+----+\n",
      "|             2.0|13450|2494|5412|\n",
      "|             1.0| 4426|8117|1752|\n",
      "|             0.0|97639|1254|1900|\n",
      "+----------------+-----+----+----+\n",
      "\n",
      "accuracy: 0.8147518395825394\n",
      "f1: 0.8419021517752977\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator(nb_test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a41e7b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.85      0.90    115515\n",
      "         1.0       0.57      0.68      0.62     11865\n",
      "         2.0       0.25      0.60      0.36      9064\n",
      "\n",
      "    accuracy                           0.81    136444\n",
      "   macro avg       0.60      0.71      0.63    136444\n",
      "weighted avg       0.89      0.81      0.84    136444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = nb_test_model.select(['label']).collect()\n",
    "y_pred = nb_test_model.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70f92d",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3285fb",
   "metadata": {},
   "source": [
    "### Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9fb6c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "622aae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(featuresCol='features',\n",
    "                        labelCol='label',\n",
    "                        predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5984a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticModel = logistic.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373cd4e",
   "metadata": {},
   "source": [
    "### Đánh giá kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28760308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for evaluating classification model\n",
    "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator\n",
    "\n",
    "accuracy= MulticlassClassificationEvaluator(labelCol= 'label', predictionCol= 'prediction', metricName= 'accuracy')\n",
    "f1= MulticlassClassificationEvaluator(labelCol= 'label', predictionCol= 'prediction', metricName= 'f1')\n",
    "\n",
    "def classification_evaluator(data_result):\n",
    "    data_result.crosstab(col1 = 'prediction', col2= 'label').show()\n",
    "    print('accuracy:' ,accuracy.evaluate(data_result))\n",
    "    print('f1:' ,f1.evaluate(data_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e26b88f",
   "metadata": {},
   "source": [
    "#### Đánh giá model dựa trên tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0fb22fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data set\n",
    "logistic_train_model= logisticModel.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50486f9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+-----+-----+\n",
      "|prediction_label|   0.0|  1.0|  2.0|\n",
      "+----------------+------+-----+-----+\n",
      "|             2.0|  2888|  791| 8140|\n",
      "|             1.0|  3048|19080| 2651|\n",
      "|             0.0|263843| 8085|11015|\n",
      "+----------------+------+-----+-----+\n",
      "\n",
      "accuracy: 0.9108784162282775\n",
      "f1: 0.9023764563845696\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator(logistic_train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65ba590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95    269779\n",
      "         1.0       0.77      0.68      0.72     27956\n",
      "         2.0       0.69      0.37      0.48     21806\n",
      "\n",
      "    accuracy                           0.91    319541\n",
      "   macro avg       0.80      0.68      0.72    319541\n",
      "weighted avg       0.90      0.91      0.90    319541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = logistic_train_model.select(['label']).collect()\n",
    "y_pred = logistic_train_model.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894117bd",
   "metadata": {},
   "source": [
    "#### Đánh giá model dựa trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d5ca6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data set\n",
    "logistic_test_model= logisticModel.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75e4aa04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+----+----+\n",
      "|prediction_label|   0.0| 1.0| 2.0|\n",
      "+----------------+------+----+----+\n",
      "|             2.0|  1592| 526|2733|\n",
      "|             1.0|  1746|7231|1252|\n",
      "|             0.0|112177|4108|5079|\n",
      "+----------------+------+----+----+\n",
      "\n",
      "accuracy: 0.8951731113130662\n",
      "f1: 0.8848614124761008\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator(logistic_test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80e46b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.97      0.95    115515\n",
      "         1.0       0.71      0.61      0.65     11865\n",
      "         2.0       0.56      0.30      0.39      9064\n",
      "\n",
      "    accuracy                           0.90    136444\n",
      "   macro avg       0.73      0.63      0.66    136444\n",
      "weighted avg       0.88      0.90      0.88    136444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = logistic_test_model.select(['label']).collect()\n",
    "y_pred = logistic_test_model.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da20a6",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6672b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4aa79afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(featuresCol = 'features',\n",
    "                            labelCol = 'label',\n",
    "                            predictionCol = 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8403c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data and call thi rfc_model\n",
    "rfc_model = rfc.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c2786b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees: 20\n",
      "Relative importance of features: (29328,[0,1,5,6,8,11,18,20,21,23,26,27,35,37,45,54,55,56,57,59,65,72,73,75,76,78,79,81,88,89,93,95,99,103,114,115,119,121,123,126,130,133,136,137,139,158,159,161,166,178,180,182,186,199,209,211,213,217,221,226,228,236,237,238,247,248,259,278,297,310,315,323,343,350,366,367,376,388,406,409,418,422,427,440,448,461,476,479,488,508,513,516,522,528,583,590,596,606,619,634,675,718,720,729,738,813,861,911,916,1019,1035,1077,1080,1206,1226,1294,1352,2062,2285,2359,2370,2582,2995,3340,3524,3796,3815,4238,5215,29327],[0.04774055246652657,1.565701482101951e-06,0.008785277082481422,0.0015072061953582347,0.03840283227496514,0.04718006597924762,0.00046278362696665554,9.197369886901566e-05,0.00029141820468749644,4.3997232483775736e-07,0.022896456216727597,0.016190405369902006,2.9799870316510524e-05,0.04863081924512774,0.0251680836896133,0.0004396924312008289,0.0006193904130989565,0.02642418903759521,1.0610758127643103e-05,0.0001717579764806153,0.0480694757245154,0.0006144656128443896,0.0003537142883108699,0.01870322174040625,0.010752227216543873,4.989736868537414e-05,0.00543920849148481,0.006129969749840999,1.931202906358208e-05,0.00012627231172635732,0.008993324232579192,1.7682032883315794e-06,0.04013801453879447,0.0003164232313138068,0.0005874738121303925,0.022373785629388795,1.6696073959713758e-05,0.0015830142206771408,0.00044783790596774275,0.005326021611695776,0.05648304871616916,1.1360569606446342e-05,0.0005511797783653452,0.008532600094379216,7.152948085051018e-05,0.047943788690326186,0.00011704766938748514,0.028607318495509897,2.8277567358303025e-06,0.00017017960434161314,2.767546618536364e-05,6.573017344695918e-05,0.05070669737171574,0.013900306909281438,0.0017586331107834505,0.00017730234930769616,0.004390583213965347,0.014205908137117687,0.00018151712026191172,5.441746777994193e-05,0.00020921820461187985,3.447780437396916e-05,0.006422554521758503,5.757839368914229e-05,0.0007593957837029885,0.005674289742077309,5.470603526379785e-05,0.004493712660996077,5.263901535190072e-05,0.0025547915281374607,0.0002083124980984229,0.00013617059910689438,0.0001083498661610582,0.002903570377068252,0.004724599731488356,0.00010126919004398898,0.021308672922509354,0.00027887973788972523,2.5549975178306686e-05,6.477480201756697e-05,0.000341881172003336,0.021775619824679106,0.03955394082503373,0.00027066139265529224,0.005813412092731772,2.2554683980569026e-05,0.00033340366989733115,0.021037727682732106,0.001404043115488435,0.001054365224199555,0.0003403595218549307,0.00014348845970830882,5.565009852494362e-05,0.00544290056000228,0.0001087292108246573,0.00017992225943887078,0.006770057527245639,7.89413388583801e-07,7.217680646906846e-05,0.011396268718994344,0.006300714628479409,0.00188650041208074,0.0013339840007618117,1.1194925361845369e-05,0.002987564978348573,0.000272216165280991,4.875758225628237e-05,0.0010221088139589038,0.0006082627736159206,0.014181902230449548,0.0007548318428859265,9.015445592941825e-05,0.0014197509413116688,0.00023755028157315948,0.02586039915463263,0.029166432495710142,0.0019762000362313404,0.00042428183905707917,7.705422557357642e-05,0.00017664992914425128,0.0006615696569084453,2.5540162582304247e-05,0.0001139991114809442,0.00464122948580826,0.016192338018481595,0.0012534401891312126,8.010663792763356e-05,0.001747245512454195,0.0006887385841918865,0.03642071889917852])\n"
     ]
    }
   ],
   "source": [
    "# Find the number of trees and the relative importance of features\n",
    "print('Number of trees:', rfc_model.getNumTrees)\n",
    "print('Relative importance of features:', rfc_model.featureImportances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a362a5",
   "metadata": {},
   "source": [
    "### Đánh giá kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14dec8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for evaluating classification model\n",
    "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator\n",
    "\n",
    "accuracy= MulticlassClassificationEvaluator(labelCol= 'label', predictionCol= 'prediction', metricName= 'accuracy')\n",
    "f1= MulticlassClassificationEvaluator(labelCol= 'label', predictionCol= 'prediction', metricName= 'f1')\n",
    "\n",
    "def classification_evaluator(data_result):\n",
    "    data_result.crosstab(col1 = 'prediction', col2= 'label').show()\n",
    "    print('accuracy:' ,accuracy.evaluate(data_result))\n",
    "    print('f1:' ,f1.evaluate(data_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2429d194",
   "metadata": {},
   "source": [
    "#### Đánh giá model dựa trên tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3d19bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data set\n",
    "rf_train_result= rfc_model.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c231218b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+-----+-----+\n",
      "|prediction_label|   0.0|  1.0|  2.0|\n",
      "+----------------+------+-----+-----+\n",
      "|             0.0|269779|27956|21806|\n",
      "+----------------+------+-----+-----+\n",
      "\n",
      "accuracy: 0.844270375319599\n",
      "f1: 0.7729804438449267\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator(rf_train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "feda888d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.92    269779\n",
      "         1.0       0.00      0.00      0.00     27956\n",
      "         2.0       0.00      0.00      0.00     21806\n",
      "\n",
      "    accuracy                           0.84    319541\n",
      "   macro avg       0.28      0.33      0.31    319541\n",
      "weighted avg       0.71      0.84      0.77    319541\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = rf_train_result.select(['label']).collect()\n",
    "y_pred = rf_train_result.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86fa93d",
   "metadata": {},
   "source": [
    "#### Đánh giá model dựa trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4906d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data set\n",
    "rf_test_result= rfc_model.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a1ba08a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+-----+----+\n",
      "|prediction_label|   0.0|  1.0| 2.0|\n",
      "+----------------+------+-----+----+\n",
      "|             0.0|115515|11865|9064|\n",
      "+----------------+------+-----+----+\n",
      "\n",
      "accuracy: 0.8466110638796869\n",
      "f1: 0.7762872296211847\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator(rf_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d937e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92    115515\n",
      "         1.0       0.00      0.00      0.00     11865\n",
      "         2.0       0.00      0.00      0.00      9064\n",
      "\n",
      "    accuracy                           0.85    136444\n",
      "   macro avg       0.28      0.33      0.31    136444\n",
      "weighted avg       0.72      0.85      0.78    136444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = rf_test_result.select(['label']).collect()\n",
    "y_pred = rf_test_result.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396c324",
   "metadata": {},
   "source": [
    "### Resample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3ab138b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio like/neutral: 9\n",
      "ratio like/not_like: 12\n"
     ]
    }
   ],
   "source": [
    "like_df = training.filter(col('label') == 0)\n",
    "neutral_df = training.filter(col('label') == 1)\n",
    "not_like_df = training.filter(col('label') == 2)\n",
    "ratio_1 = int(like_df.count()/neutral_df.count())\n",
    "ratio_2 = int(like_df.count()/not_like_df.count())\n",
    "print('ratio like/neutral: {}'.format(ratio_1))\n",
    "print('ratio like/not_like: {}'.format(ratio_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0771fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resample neutral\n",
    "a1 = range(ratio_1)\n",
    "# duplicate the minority rows\n",
    "oversampled_neutral_df = neutral_df.withColumn('dummy',explode(array([lit(x) for x in a1]))).drop('dummy')\n",
    "# combine both oversampled minority rows  and previous majority rows\n",
    "combined_df = like_df.unionAll(oversampled_neutral_df)\n",
    "combined_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e593aaf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|  0.0|269779|\n",
      "|  1.0|251604|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f30f0d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "|  0.0|(29328,[0,1,2,3,4...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resample not_like\n",
    "a2 = range(ratio_2)\n",
    "# Duplicate the minority rows\n",
    "oversampled_notlike_df = not_like_df.withColumn('dummy',explode(array([lit(x) for x in a2]))).drop('dummy')\n",
    "# combine both oversampled minority rows  and previous majority rows\n",
    "combined_df = combined_df.unionAll(oversampled_notlike_df)\n",
    "combined_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d66fa51c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|  0.0|269779|\n",
      "|  1.0|251604|\n",
      "|  2.0|261672|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2dba0",
   "metadata": {},
   "source": [
    "## NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec918299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "546f4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use defauls\n",
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1076bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbModel_2 = nb.fit(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e34ba9",
   "metadata": {},
   "source": [
    "### Đánh giá kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af835cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for evaluating classification model\n",
    "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator\n",
    "\n",
    "accuracy= MulticlassClassificationEvaluator(labelCol= 'label', predictionCol= 'prediction', metricName= 'accuracy')\n",
    "f1= MulticlassClassificationEvaluator(labelCol= 'label', predictionCol= 'prediction', metricName= 'f1')\n",
    "\n",
    "def classification_evaluator(data_result):\n",
    "    data_result.crosstab(col1 = 'prediction', col2= 'label').show()\n",
    "    print('accuracy:' ,accuracy.evaluate(data_result))\n",
    "    print('f1:' ,f1.evaluate(data_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8627e06",
   "metadata": {},
   "source": [
    "#### Đánh giá model dựa trên tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed67a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data set\n",
    "nb_train_model= nbModel_2.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "866953b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+-----+-----+\n",
      "|prediction_label|   0.0|  1.0|  2.0|\n",
      "+----------------+------+-----+-----+\n",
      "|             2.0| 36981| 6551|16748|\n",
      "|             1.0|  9868|19988| 2987|\n",
      "|             0.0|222930| 1417| 2071|\n",
      "+----------------+------+-----+-----+\n",
      "\n",
      "accuracy: 0.812621854472509\n",
      "f1: 0.8439938347899083\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator(nb_train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bdca641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.83      0.90    269779\n",
      "         1.0       0.61      0.71      0.66     27956\n",
      "         2.0       0.28      0.77      0.41     21806\n",
      "\n",
      "    accuracy                           0.81    319541\n",
      "   macro avg       0.62      0.77      0.65    319541\n",
      "weighted avg       0.90      0.81      0.84    319541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = nb_train_model.select(['label']).collect()\n",
    "y_pred = nb_train_model.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e315e6e",
   "metadata": {},
   "source": [
    "#### Đánh giá model dựa trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4d1d4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data set\n",
    "nb_test_model= nbModel_2.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7063f5d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----+----+\n",
      "|prediction_label|  0.0| 1.0| 2.0|\n",
      "+----------------+-----+----+----+\n",
      "|             2.0|16876|3169|6237|\n",
      "|             1.0| 4431|7795|1625|\n",
      "|             0.0|94208| 901|1202|\n",
      "+----------------+-----+----+----+\n",
      "\n",
      "accuracy: 0.7932924862947436\n",
      "f1: 0.8292092457230863\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator(nb_test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ddcbf0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.82      0.89    115515\n",
      "         1.0       0.56      0.66      0.61     11865\n",
      "         2.0       0.24      0.69      0.35      9064\n",
      "\n",
      "    accuracy                           0.79    136444\n",
      "   macro avg       0.59      0.72      0.62    136444\n",
      "weighted avg       0.89      0.79      0.83    136444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = nb_test_model.select(['label']).collect()\n",
    "y_pred = nb_test_model.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb7693",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bbb16",
   "metadata": {},
   "source": [
    "### Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "51808366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fdf94f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(featuresCol='features',\n",
    "                        labelCol='label',\n",
    "                        predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f21f5b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticModel_2 = logistic.fit(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba200d95",
   "metadata": {},
   "source": [
    "### Đánh giá kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55e7ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for evaluating classification model\n",
    "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator\n",
    "\n",
    "accuracy= MulticlassClassificationEvaluator(labelCol= 'label', predictionCol= 'prediction', metricName= 'accuracy')\n",
    "f1= MulticlassClassificationEvaluator(labelCol= 'label', predictionCol= 'prediction', metricName= 'f1')\n",
    "\n",
    "def classification_evaluator(data_result):\n",
    "    data_result.crosstab(col1 = 'prediction', col2= 'label').show()\n",
    "    print('accuracy:' ,accuracy.evaluate(data_result))\n",
    "    print('f1:' ,f1.evaluate(data_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f0ee7",
   "metadata": {},
   "source": [
    "#### Đánh giá model dựa trên tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "809429eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data set\n",
    "logistic_train_model= logisticModel_2.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93a6cccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+-----+-----+\n",
      "|prediction_label|   0.0|  1.0|  2.0|\n",
      "+----------------+------+-----+-----+\n",
      "|             2.0| 28975| 5254|16084|\n",
      "|             1.0|  8156|21587| 3441|\n",
      "|             0.0|232648| 1115| 2281|\n",
      "+----------------+------+-----+-----+\n",
      "\n",
      "accuracy: 0.8459602993043146\n",
      "f1: 0.8688448292985071\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator(logistic_train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5d620f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.86      0.92    269779\n",
      "         1.0       0.65      0.77      0.71     27956\n",
      "         2.0       0.32      0.74      0.45     21806\n",
      "\n",
      "    accuracy                           0.85    319541\n",
      "   macro avg       0.65      0.79      0.69    319541\n",
      "weighted avg       0.91      0.85      0.87    319541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = logistic_train_model.select(['label']).collect()\n",
    "y_pred = logistic_train_model.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2938adc",
   "metadata": {},
   "source": [
    "#### Đánh giá model dựa trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "34555c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data set\n",
    "logistic_test_model= logisticModel_2.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea3d7f7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----+----+\n",
      "|prediction_label|  0.0| 1.0| 2.0|\n",
      "+----------------+-----+----+----+\n",
      "|             2.0|13250|2673|5785|\n",
      "|             1.0| 3967|8206|1792|\n",
      "|             0.0|98298| 986|1487|\n",
      "+----------------+-----+----+----+\n",
      "\n",
      "accuracy: 0.8229676643897863\n",
      "f1: 0.8497677114428563\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator(logistic_test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dbea63a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.85      0.91    115515\n",
      "         1.0       0.59      0.69      0.64     11865\n",
      "         2.0       0.27      0.64      0.38      9064\n",
      "\n",
      "    accuracy                           0.82    136444\n",
      "   macro avg       0.61      0.73      0.64    136444\n",
      "weighted avg       0.89      0.82      0.85    136444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = logistic_test_model.select(['label']).collect()\n",
    "y_pred = logistic_test_model.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b7b3dc",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7083174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0925c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(featuresCol = 'features',\n",
    "                            labelCol = 'label',\n",
    "                            predictionCol = 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e45b298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data and call thi rfc_model\n",
    "rfc_model_2 = rfc.fit(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4b1d4e81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees: 20\n",
      "Relative importance of features: (29328,[0,1,5,6,8,11,18,20,21,23,26,27,35,37,45,54,55,56,57,59,65,72,73,75,76,78,79,81,88,89,93,95,99,103,114,115,119,121,123,126,130,133,136,137,139,158,159,161,166,178,180,182,186,199,209,211,213,217,221,226,228,236,237,238,247,248,259,278,297,310,315,323,343,350,366,367,376,388,406,409,418,422,427,440,448,461,476,479,488,508,513,516,522,528,583,590,596,606,619,634,675,718,720,729,738,813,861,911,916,1019,1035,1077,1080,1206,1226,1294,1352,2062,2285,2359,2370,2582,2995,3340,3524,3796,3815,4238,5215,29327],[0.04774055246652657,1.565701482101951e-06,0.008785277082481422,0.0015072061953582347,0.03840283227496514,0.04718006597924762,0.00046278362696665554,9.197369886901566e-05,0.00029141820468749644,4.3997232483775736e-07,0.022896456216727597,0.016190405369902006,2.9799870316510524e-05,0.04863081924512774,0.0251680836896133,0.0004396924312008289,0.0006193904130989565,0.02642418903759521,1.0610758127643103e-05,0.0001717579764806153,0.0480694757245154,0.0006144656128443896,0.0003537142883108699,0.01870322174040625,0.010752227216543873,4.989736868537414e-05,0.00543920849148481,0.006129969749840999,1.931202906358208e-05,0.00012627231172635732,0.008993324232579192,1.7682032883315794e-06,0.04013801453879447,0.0003164232313138068,0.0005874738121303925,0.022373785629388795,1.6696073959713758e-05,0.0015830142206771408,0.00044783790596774275,0.005326021611695776,0.05648304871616916,1.1360569606446342e-05,0.0005511797783653452,0.008532600094379216,7.152948085051018e-05,0.047943788690326186,0.00011704766938748514,0.028607318495509897,2.8277567358303025e-06,0.00017017960434161314,2.767546618536364e-05,6.573017344695918e-05,0.05070669737171574,0.013900306909281438,0.0017586331107834505,0.00017730234930769616,0.004390583213965347,0.014205908137117687,0.00018151712026191172,5.441746777994193e-05,0.00020921820461187985,3.447780437396916e-05,0.006422554521758503,5.757839368914229e-05,0.0007593957837029885,0.005674289742077309,5.470603526379785e-05,0.004493712660996077,5.263901535190072e-05,0.0025547915281374607,0.0002083124980984229,0.00013617059910689438,0.0001083498661610582,0.002903570377068252,0.004724599731488356,0.00010126919004398898,0.021308672922509354,0.00027887973788972523,2.5549975178306686e-05,6.477480201756697e-05,0.000341881172003336,0.021775619824679106,0.03955394082503373,0.00027066139265529224,0.005813412092731772,2.2554683980569026e-05,0.00033340366989733115,0.021037727682732106,0.001404043115488435,0.001054365224199555,0.0003403595218549307,0.00014348845970830882,5.565009852494362e-05,0.00544290056000228,0.0001087292108246573,0.00017992225943887078,0.006770057527245639,7.89413388583801e-07,7.217680646906846e-05,0.011396268718994344,0.006300714628479409,0.00188650041208074,0.0013339840007618117,1.1194925361845369e-05,0.002987564978348573,0.000272216165280991,4.875758225628237e-05,0.0010221088139589038,0.0006082627736159206,0.014181902230449548,0.0007548318428859265,9.015445592941825e-05,0.0014197509413116688,0.00023755028157315948,0.02586039915463263,0.029166432495710142,0.0019762000362313404,0.00042428183905707917,7.705422557357642e-05,0.00017664992914425128,0.0006615696569084453,2.5540162582304247e-05,0.0001139991114809442,0.00464122948580826,0.016192338018481595,0.0012534401891312126,8.010663792763356e-05,0.001747245512454195,0.0006887385841918865,0.03642071889917852])\n"
     ]
    }
   ],
   "source": [
    "# Find the number of trees and the relative importance of features\n",
    "print('Number of trees:', rfc_model.getNumTrees)\n",
    "print('Relative importance of features:', rfc_model.featureImportances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901f9a4",
   "metadata": {},
   "source": [
    "### Đánh giá kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b150b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for evaluating classification model\n",
    "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator\n",
    "\n",
    "accuracy= MulticlassClassificationEvaluator(labelCol= 'label', predictionCol= 'prediction', metricName= 'accuracy')\n",
    "f1= MulticlassClassificationEvaluator(labelCol= 'label', predictionCol= 'prediction', metricName= 'f1')\n",
    "\n",
    "def classification_evaluator(data_result):\n",
    "    data_result.crosstab(col1 = 'prediction', col2= 'label').show()\n",
    "    print('accuracy:' ,accuracy.evaluate(data_result))\n",
    "    print('f1:' ,f1.evaluate(data_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea77e3",
   "metadata": {},
   "source": [
    "#### Đánh giá model dựa trên tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8443120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data set\n",
    "rf_train_result= rfc_model_2.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0534d67a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+-----+-----+\n",
      "|prediction_label|   0.0|  1.0|  2.0|\n",
      "+----------------+------+-----+-----+\n",
      "|             2.0| 35397| 8278| 9144|\n",
      "|             1.0|  3670| 6663| 1310|\n",
      "|             0.0|230712|13015|11352|\n",
      "+----------------+------+-----+-----+\n",
      "\n",
      "accuracy: 0.7714784644224059\n",
      "f1: 0.7883978374982236\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator(rf_train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e56504b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.86      0.88    269779\n",
      "         1.0       0.57      0.24      0.34     27956\n",
      "         2.0       0.17      0.42      0.25     21806\n",
      "\n",
      "    accuracy                           0.77    319541\n",
      "   macro avg       0.55      0.50      0.49    319541\n",
      "weighted avg       0.83      0.77      0.79    319541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = rf_train_result.select(['label']).collect()\n",
    "y_pred = rf_train_result.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35774f38",
   "metadata": {},
   "source": [
    "#### Đánh giá model dựa trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dbcb5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data set\n",
    "rf_test_result= rfc_model_2.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8321dec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----+----+\n",
      "|prediction_label|  0.0| 1.0| 2.0|\n",
      "+----------------+-----+----+----+\n",
      "|             2.0|15035|3603|3721|\n",
      "|             1.0| 1553|2699| 532|\n",
      "|             0.0|98927|5563|4811|\n",
      "+----------------+-----+----+----+\n",
      "\n",
      "accuracy: 0.7720896485004837\n",
      "f1: 0.7890046267281347\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator(rf_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2e7aca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88    115515\n",
      "         1.0       0.56      0.23      0.32     11865\n",
      "         2.0       0.17      0.41      0.24      9064\n",
      "\n",
      "    accuracy                           0.77    136444\n",
      "   macro avg       0.55      0.50      0.48    136444\n",
      "weighted avg       0.83      0.77      0.79    136444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = rf_test_result.select(['label']).collect()\n",
    "y_pred = rf_test_result.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e62c0",
   "metadata": {},
   "source": [
    "## Kết luận:\n",
    "- Resample data không mang lại kết quả tốt hơn\n",
    "- Model mang lại kết quả tốt nhất là Logistic Regression (acc = 89%) => lựa chọn model này"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277bce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
